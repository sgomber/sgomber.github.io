<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Shaurya Gomber</title> <meta name="author" content="Shaurya Gomber"/> <meta name="description" content="Profile website of Shaurya Gomber. "/> <meta name="keywords" content="academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://sgomber.github.io/publications/"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter nav-title-col" href="https://sgomber.github.io/"><span class="special nav-title-col">Shaurya</span> Gomber</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">Talks</a> </li> <li class="nav-item "> <a class="nav-link" href="/more/">More</a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <p class="post-title section-title">Preprints</p> <ul class="list-group"> <li class="list-group-item"> <div class="title paper-title"> Unified Operational Formalism for LLM-based Theorem-proving Systems </div> <div class="authors"> Avaljot Singh*, <span class="author-font">Shaurya Gomber*</span>, Yasmin Sarita, Jos√© Meseguer, Gagandeep Singh </div> <div> <div> <a class="paper-links" href="#" data-bs-toggle="collapse" data-bs-target="#abstract-0-unified-operational-formalism-for-llm-based-theorem-proving-systems" aria-expanded="false" aria-controls="abstract-0-unified-operational-formalism-for-llm-based-theorem-proving-systems">Abstract</a>¬†<span class="small-slash">/</span>¬†<a class="paper-links" href="/assets/pdf/papers_posters/Unified_Theorem_Proving.pdf" target="_blank">Paper</a> </div> <div class="collapse abstract-block" id="abstract-0-unified-operational-formalism-for-llm-based-theorem-proving-systems"> <p class="abstract-text"> LLM-based theorem provers differ widely in how they organise interaction between language models and interactive theorem provers, ranging from whole-proof generation to tactic-level and multi-stage pipelines. We propose a unified operational framework that makes this interaction structure explicit by modelling proof search as transitions over a joint formal and informal state and by introducing orchestration as a first-class abstraction that controls how tools such as language models, retrieval components, and provers are scheduled and coordinated. Within this framework, existing systems such as Baldur, COPRA, DSP, POETRY, etc, can be expressed uniformly as different orchestration strategies, enabling principled comparison of interaction patterns, rapid prototyping of new strategies, and backend-agnostic evaluation and reuse across provers, libraries, and models. </p> </div> </div> </li> <li class="list-group-item"> <div class="title paper-title"> Universal Synthesis of Differentiably Tunable Numerical Abstract Transformers </div> <div class="authors"> <span class="author-font">Shaurya Gomber</span>, Debangshu Banerjee, Gagandeep Singh </div> <div> <div> <a class="paper-links" href="#" data-bs-toggle="collapse" data-bs-target="#abstract-1-universal-synthesis-of-differentiably-tunable-numerical-abstract-transformers" aria-expanded="false" aria-controls="abstract-1-universal-synthesis-of-differentiably-tunable-numerical-abstract-transformers">Abstract</a>¬†<span class="small-slash">/</span>¬†<a class="paper-links" href="https://arxiv.org/abs/2507.11827" target="_blank" rel="noopener noreferrer">Arxiv</a>¬†<span class="small-slash">/</span>¬†<a class="paper-links" href="#" data-bs-toggle="collapse" data-bs-target="#bibtex-1-universal-synthesis-of-differentiably-tunable-numerical-abstract-transformers" aria-expanded="false" aria-controls="bibtex-1-universal-synthesis-of-differentiably-tunable-numerical-abstract-transformers">BibTeX</a> </div> <div class="collapse abstract-block" id="abstract-1-universal-synthesis-of-differentiably-tunable-numerical-abstract-transformers"> <p class="abstract-text"> Numerical abstract interpretation is a widely used framework for the static analysis of numerical programs. However, existing numerical abstract interpreters rely on hand-crafted, instruction-specific transformers tailored to each domain, with no general algorithm for handling common operations across domains. This limits extensibility, prevents precise compositional reasoning over instruction sequences, and forces all downstream tasks to use the same fixed transformer regardless of their precision, efficiency, or task-specific requirements. To address these limitations, we propose a universal transformer synthesis algorithm that constructs a parametric family of sound abstract transformers for any given polyhedral numerical domain and a concrete operator from the class of Quadratic-Bounded Guarded Operators (QGO), which includes both individual instructions and structured sequences. Each instantiation in this family is sound by construction, enabling downstream analyses to adapt the transformer to their particular needs. The space of transformers is differentiable but complex. To efficiently explore this space of transformers, we introduce the Adaptive Gradient Guidance (AGG) procedure, a gradient-guided search strategy that steers the search process based on downstream analysis objectives and runtime constraints. We implement these ideas in the USTAD framework and evaluate their effectiveness across three numerical abstract domains: Zones, Octagons, and Polyhedra. Our results demonstrate that the universal synthesis algorithm successfully constructs sound families of transformers across domains, and that USTAD achieves significant, tunable precision gains over baselines by leveraging compositional reasoning and efficient gradient-guided traversal of the transformer space. </p> </div> <div class="collapse bibtex-block mt-2" id="bibtex-1-universal-synthesis-of-differentiably-tunable-numerical-abstract-transformers"> <pre id="bibtex-content-bibtex-1-universal-synthesis-of-differentiably-tunable-numerical-abstract-transformers">@misc{ustad_arxiv,
    title={Universal Synthesis of Differentiably Tunable Numerical Abstract Transformers}, 
    author={Shaurya Gomber and Debangshu Banerjee and Gagandeep Singh},
    year={2025},
    eprint={2507.11827},
    archivePrefix={arXiv},
    primaryClass={cs.PL},
    note={\url{https://arxiv.org/abs/2507.11827}}, 
}
</pre> </div> </div> </li> </ul> <p class="post-title section-title">Conferences</p> <ul class="list-group"> <li class="list-group-item"> <div class="title paper-title"> Efficient Ranking Function-Based Termination Analysis via Bidirectional Decompositional Search </div> <div class="authors"> Yasmin Chandini Sarita, Avaljot Singh, <span class="author-font">Shaurya Gomber</span>, Gagandeep Singh, Mahesh Viswanathan </div> <div class="venue"> <a href="https://etaps.org/2026/conferences/esop/" target="_blank" rel="noopener noreferrer noopener noreferrer">ESOP 2026</a> </div> <div> <div> <a class="paper-links" href="#" data-bs-toggle="collapse" data-bs-target="#abstract-0-efficient-ranking-function-based-termination-analysis-via-bidirectional-decompositional-search" aria-expanded="false" aria-controls="abstract-0-efficient-ranking-function-based-termination-analysis-via-bidirectional-decompositional-search">Abstract</a>¬†<span class="small-slash">/</span>¬†<a class="paper-links" href="https://arxiv.org/abs/2404.05951" target="_blank" rel="noopener noreferrer">Arxiv</a>¬†<span class="small-slash">/</span>¬†<a class="paper-links" href="https://github.com/uiuc-focal-lab/Syndicate" target="_blank" rel="noopener noreferrer">Code</a>¬†<span class="small-slash">/</span>¬†<a class="paper-links" href="#" data-bs-toggle="collapse" data-bs-target="#bibtex-0-efficient-ranking-function-based-termination-analysis-via-bidirectional-decompositional-search" aria-expanded="false" aria-controls="bibtex-0-efficient-ranking-function-based-termination-analysis-via-bidirectional-decompositional-search">BibTeX</a> </div> <div class="collapse abstract-block" id="abstract-0-efficient-ranking-function-based-termination-analysis-via-bidirectional-decompositional-search"> <p class="abstract-text"> Synthesizing ranking functions is a common technique for proving the termination of loops in programs. A ranking function must be bounded and decrease by a specified amount with each iteration for all reachable program states. Since the set of reachable states is unknown, loop invariants are used to overapproximate it, requiring the joint synthesis of ranking functions and invariants to prove the ranking functions valid. Existing approaches either synthesize them independently, encode them into a single monolithic query, or connect them through ad hoc, one-way information flow, leading to inefficient exploration of large search spaces. We present Syndicate, a termination analysis framework based on the novel concept of Bidirectional Decompositional Search (BDS). BDS keeps ranking-function and invariant synthesis decomposed but ensures that they co-evolve through continuous bi-directional feedback. This mutual guidance enables efficient exploration and significantly increases the number of programs proven to terminate while reducing runtime compared to baselines without such feedback. Depending on the templates used, Syndicate is both relatively complete and efficient, outperforming existing techniques that achieve at most one of these guarantees. Despite its simplicity, Syndicate matches or surpasses state-of-the-art tools in termination proofs and runtime, demonstrating the effectiveness of bi-directional reasoning in termination analysis. </p> </div> <div class="collapse bibtex-block mt-2" id="bibtex-0-efficient-ranking-function-based-termination-analysis-via-bidirectional-decompositional-search"> <pre id="bibtex-content-bibtex-0-efficient-ranking-function-based-termination-analysis-via-bidirectional-decompositional-search">@misc{
    syndicate_arxiv,
    title={Efficient Ranking Function-Based Termination Analysis with Bi-Directional Feedback}, 
    author={Yasmin Sarita and Avaljot Singh and Shaurya Gomber and Gagandeep Singh and Mahesh Vishwanathan},
    year={2024},
    eprint={2404.05951},
    archivePrefix={arXiv},
    primaryClass={cs.LO},
    url={https://arxiv.org/abs/2404.05951}, 
}
</pre> </div> </div> </li> </ul> <p class="post-title section-title">Workshops</p> <ul class="list-group"> <li class="list-group-item"> <div class="title paper-title"> Neural Abstract Interpretation </div> <div class="authors"> <span class="author-font">Shaurya Gomber</span>, Gagandeep Singh </div> <div class="venue"> <a href="https://verifai-workshop.github.io/" target="_blank" rel="noopener noreferrer noopener noreferrer">VerifAI @ ICLR 2025</a> | <a href="https://pldi24.sigplan.org/track/pldi-2024-src" target="_blank" rel="noopener noreferrer noopener noreferrer">SRC @ PLDI 2024</a> </div> <div> <div> <a class="paper-links" href="#" data-bs-toggle="collapse" data-bs-target="#abstract-0-neural-abstract-interpretation" aria-expanded="false" aria-controls="abstract-0-neural-abstract-interpretation">Abstract</a>¬†<span class="small-slash">/</span>¬†<a class="paper-links" href="/assets/pdf/papers_posters/VerifAI_ICLR_25_NAI.pdf" target="_blank">Paper</a>¬†<span class="small-slash">/</span>¬†<a class="paper-links" href="/assets/pdf/papers_posters/NAI_SRC_Poster.pdf" target="_blank">Poster</a>¬†<span class="small-slash">/</span>¬†<a class="paper-links" href="#" data-bs-toggle="collapse" data-bs-target="#bibtex-0-neural-abstract-interpretation" aria-expanded="false" aria-controls="bibtex-0-neural-abstract-interpretation">BibTeX</a> </div> <div class="collapse abstract-block" id="abstract-0-neural-abstract-interpretation"> <p class="abstract-text"> Abstract interpretation is a widely used method for the formal analysis and verification of programs and neural networks. However, designing efficient abstract transformers for expressive relational domains such as Octagon and Polyhedra is challenging as one needs to carefully balance the fundamental trade-off between the cost, soundness, and precision of the transformer for downstream tasks. Further, scalable implementations involve intricate performance optimizations like Octagon and Polyhedra decomposition. Given the inherent complexity of abstract transformers and the proven capability of neural networks to effectively approximate complex functions, we envision and propose the concept of Neural Abstract Transformers: neural networks that serve as abstract transformers. The proposed Neural Abstract Interpretation (NAI) framework provides supervised and unsupervised methods to learn efficient neural transformers automatically, which reduces development costs. We instantiate the NAI framework for two widely used numerical domains: Interval and Octagon. Evaluations on these domains demonstrate the effectiveness of the NAI framework to learn sound and precise neural transformers. An added advantage of our technique is that neural transformers are differentiable, unlike hand-crafted alternatives. As an example, we showcase how this differentiability allows framing invariant generation as a learning problem, enabling neural transformers to generate valid octagonal invariants for a program. </p> </div> <div class="collapse bibtex-block mt-2" id="bibtex-0-neural-abstract-interpretation"> <pre id="bibtex-content-bibtex-0-neural-abstract-interpretation">@inproceedings{gomber2025neural,
               title={Neural Abstract Interpretation},
               author={Shaurya Gomber and Gagandeep Singh},
               booktitle={ICLR 2025 Workshop: VerifAI: AI Verification in the Wild},
               year={2025},
               url={https://openreview.net/forum?id=WTyyhWhp4m}
}
</pre> </div> </div> </li> </ul> <p class="post-title section-title">Thesis</p> <ul class="list-group"> <li class="list-group-item"> <div class="title paper-title"> Neural Abstract Interpretation: Leveraging neural networks for automated, efficient and differentiable abstract interpretation </div> <div class="authors"> </div> <div class="venue"> <a href="https://www.ideals.illinois.edu/items/131524" target="_blank" rel="noopener noreferrer noopener noreferrer">MS Thesis 2024 (UIUC)</a> </div> <span class="paper-award"> <span style="font-size: 0.95rem; color: #f8d775;">üèÜ</span> <a href="https://siebelschool.illinois.edu/about/awards/graduate-fellowships-awards/david-j-kuck-outstanding-thesis-awards" target="_blank" rel="noopener noreferrer noopener noreferrer" class="paper-award-badge"> David J. Kuck Outstanding Master‚Äôs Thesis Award 2024 </a> </span> <div> <div> <a class="paper-links" href="https://www.ideals.illinois.edu/items/131524" target="_blank" rel="noopener noreferrer">Thesis</a>¬†<span class="small-slash">/</span>¬†<a class="paper-links" href="#" data-bs-toggle="collapse" data-bs-target="#bibtex-0-neural-abstract-interpretation-leveraging-neural-networks-for-automated-efficient-and-differentiable-abstract-interpretation" aria-expanded="false" aria-controls="bibtex-0-neural-abstract-interpretation-leveraging-neural-networks-for-automated-efficient-and-differentiable-abstract-interpretation">BibTeX</a> </div> <div class="collapse bibtex-block mt-2" id="bibtex-0-neural-abstract-interpretation-leveraging-neural-networks-for-automated-efficient-and-differentiable-abstract-interpretation"> <pre id="bibtex-content-bibtex-0-neural-abstract-interpretation-leveraging-neural-networks-for-automated-efficient-and-differentiable-abstract-interpretation">@mastersthesis{
    nai_gomber_2024,
    title={Neural abstract interpretation: Leveraging neural networks for automated,
           efficient and differentiable abstract interpretation},
    author={Gomber, Shaurya},
    year={2024},
    school={University of Illinois at Urbana-Champaign},
    url={https://www.ideals.illinois.edu/items/131524}
}
</pre> </div> </div> </li> </ul> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> ¬© 2026 Shaurya Gomber. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Last updated: February 14, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-FRMNFKQVN7"></script> <script>if("localhost"!==location.hostname&&"127.0.0.1"!==location.hostname){function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-FRMNFKQVN7")}</script> </body> </html>